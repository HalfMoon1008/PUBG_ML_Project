{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    #start_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    #end_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    #print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_V2.csv')\n",
    "train = reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = pd.read_csv('data/featured_train_1.csv')\n",
    "train1 = reduce_mem_usage(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = pd.read_csv('data/featured_train_2.csv')\n",
    "train2 = reduce_mem_usage(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = pd.read_csv('data/featured_train_3.csv')\n",
    "train3 = reduce_mem_usage(train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train4 = pd.read_csv('data/featured_train_4.csv')\n",
    "train4 = reduce_mem_usage(train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "train4 = train4.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/sanghyun/Desktop/Coding/PUBG_ML_Project/3th-4thModeling.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sanghyun/Desktop/Coding/PUBG_ML_Project/3th-4thModeling.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sanghyun/Desktop/Coding/PUBG_ML_Project/3th-4thModeling.ipynb#ch0000007?line=1'>2</a>\u001b[0m train1 \u001b[39m=\u001b[39m train1\u001b[39m.\u001b[39mrename(columns \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x:re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[^A-Za-z0-9_]+\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, x))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sanghyun/Desktop/Coding/PUBG_ML_Project/3th-4thModeling.ipynb#ch0000007?line=2'>3</a>\u001b[0m train2 \u001b[39m=\u001b[39m train2\u001b[39m.\u001b[39mrename(columns \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x:re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[^A-Za-z0-9_]+\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, x))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sanghyun/Desktop/Coding/PUBG_ML_Project/3th-4thModeling.ipynb#ch0000007?line=3'>4</a>\u001b[0m train3 \u001b[39m=\u001b[39m train3\u001b[39m.\u001b[39mrename(columns \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x:re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[^A-Za-z0-9_]+\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, x))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train1' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "train1 = train1.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "train2 = train2.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "train3 = train3.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "train4 = train4.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3557572, 20), (889393, 20), (3557572,), (889393,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train1.drop(columns='winPlacePerc')\n",
    "y = train1['winPlacePerc']\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06390041926718079"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "mean_absolute_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3557572, 17), (889393, 17), (3557572,), (889393,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train2.drop(columns='winPlacePerc')\n",
    "y = train2['winPlacePerc']\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06808530824631952"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "mean_absolute_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1618749, 19), (404688, 19), (1618749,), (404688,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train3.drop(columns='winPlacePerc')\n",
    "y = train3['winPlacePerc']\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08076478777275554"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "mean_absolute_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1621395, 46), (405349, 46), (1621395,), (405349,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train4.drop(columns='winPlacePerc')\n",
    "y = train4['winPlacePerc']\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046706629722549034"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "mean_absolute_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do\n",
    "- 4차까지 한 데이터들 정리\n",
    "- LGBM\n",
    "- H2O\n",
    "- HyperParameter Tuning\n",
    "- WandB\n",
    "- Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1621395, 46), (405349, 46), (1621395,), (405349,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train4.drop(columns='winPlacePerc')\n",
    "y = train4['winPlacePerc']\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046706629722549034"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "mean_absolute_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 12))\n",
    "# plot_importance(, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- num_iteration [default=100] : 반복 수행하기 위한 트리의 개수 지정. 크게 지정할수록 예측 성능이 높아질 수 있지만 과적합 문제 가능성 또한 높아짐.<br><br>\n",
    "- learning_rate [default=0.1] : 0~1 사이의 값을 지정해 부스팅 스텝을 반복적으로 수행할 때 업데이트 되는 학습률 값.<br>일반적으로 n_estimators를 크게하고 learning_rate을 작게 해서 예측 성능 향상 가능, 과적합 이슈 동반.<br><br>\n",
    "- max_depth [default=-1]: 0보다 작은 값을 지정하면 깊이에 제한 없음.<br><br>\n",
    "- min_data_in_leaf [default=20] : 결정 트리의 min_samples_leaf와 동일. <br>최종 결정 클래스인 리프 노드가 되기 위해 최소한으로 필요한 레코드 수. (과적합 방지용)<br><br>\n",
    "- num_leaves [default=32] : 하나의 트리가 가질 수 있는 최대 리프 수<br><br>\n",
    "- boosting [default=gbdt] : 부스팅 트리를 생성하는 알고리즘 (gbdt:일반적인 그래디언트 부스팅, rf:랜덤포레스트)<br><br>\n",
    "- bagging_fraction [default=1.0] : 트리가 커져서 과적합 되는 것을 방지하기 위한 데이터 샘플링 비율.<br><br>\n",
    "- feature_fraction [default=1.0] : 개별 트리를 학습할 때 무작위로 선택되는 피처의 비율 (GBM의 max_features와 동일)<br><br>\n",
    "- lambda_I2 [default=0.0] : L2 regulation 제어를 위한 값. 피처 개수가 많을 경우 적용 검토. 값이 클수록 과적합 감소 효과<br><br>\n",
    "- lambda_I1[default=0.0] : L1 regulation 제어를 위한 값. 과적합 방지용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf3ad073ee54fe618f028f20979c6d93bf2de419467b5c87f8cf480ac49fd2db"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('yeardream')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
